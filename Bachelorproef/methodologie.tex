%%=============================================================================
%% Methodologie
%%=============================================================================

\chapter{Methodologie}
\label{ch:methodologie}

%% TODO: Hoe ben je te werk gegaan? Verdeel je onderzoek in grote fasen, en
%% licht in elke fase toe welke stappen je gevolgd hebt. Verantwoord waarom je
%% op deze manier te werk gegaan bent. Je moet kunnen aantonen dat je de best
%% mogelijke manier toegepast hebt om een antwoord te vinden op de
%% onderzoeksvraag.

\section{Literatuurstudie}

\textbf{INLEIDING LITERATUURSTUDIE}

\subsection{Installatie}
\label{Installatie}

Elasticsearch is gratis als je beslist om zelf te hosten. De installatie verloopt zeer snel. Eerst moet je zorgen dat Java geïnstalleerd staat op je computer. Daarna download je een versie van Elasticsearch naar keuze via hun website. Pak het bestand uit en je bent klaar om je eerste node op te starten. Als dat te moeilijk is kan men gebruik maken van een grafische user interface die beschikbaar is via de MSI installer package. Op hun website staat stap voor stap uitgelegd hoe je de installatie kunt uitvoeren. 

Er hangen niet zoveel nadelen vast aan het zelf hosten van Elasticsearch. Ten eerste moet je over voldoende ruimte beschikken op je harde schijf. Dat kan moeilijk worden wanneer men met grote hoeveelheden data werkt. Ten tweede is het belangrijk om te weten dat je zelf verantwoordelijk bent voor eventuele downtimes. Het is dus perfect mogelijk om Elasticsearch volledig gratis te gebruiken. 

Wanneer men beslist om te betalen voor de hosting bij Elasticsearch krijgt men enkele voordelen mee. De eerder vermelde problemen in verband met ruimte op je harde schijf en downtimes zijn niet langer van toepassing.  Aan de hosting zijn een aantal Service Level Agreements gebonden die ervoor zorgen dat je verzekerd bent op een goede kwaliteit en op voldoende support. De kostprijs is 36,53 EUR per maand. Er is ook een mogelijkheid om vooraf een proefversie van 14 dagen te gebruiken.

\subsection{Data importeren in Elasticsearch}

Om data te exporteren van uw databank naar Elasticsearch zijn er een aantal mogelijkheden, afhankelijk van welke databank u gebruikt. De eerste mogelijkheid is er één die Elasticsearch zelf aanbiedt. Daarvoor maken ze gebruik van een ander product uit de Elastic Stack\footnote{De Elastic Stack is een verzameling van open-source producten van Elastic.}: Logstash. Logstash is een tool om data te verwerken, te transformeren en uit te wisselen. Het is een product waar veel informatie en support over te vinden is. Logstash is dus een tool die veel flexibiliteit biedt maar vraagt wel een extra installatie. 

Daarnaast zijn er een aantal tools die aangeboden worden door de community. Van die tools is er in het algemeen minder support te vinden. Nog een nadeel is dat het niet altijd mogelijk is om uw data naar de laatste versie van Elasticsearch te exporteren. De versies van de tools lopen namelijk in het algemeen achter op de nieuwste versie van Elasticsearch. 

Zowel Logstash als de meeste tools die worden aangeboden door de community bieden ook de functionaliteit aan om data te synchroniseren. Dat wil zeggen dat, wanneer uw data veranderd in uw databank, die veranderingen ook doorgevoerd worden in Elasticsearch. In veel use cases zal dit veel voordelen bieden. 

\textbf{VERDERE LITERATUURSTUDIE}

\section{Casus}

Om enkele voor- en nadelen uit de literatuurstudie te bevestigen of te ontkrachten heb ik een project opgezet in Elasticsearch. In het project voerde ik een aantal data-analyses uit met als doel een antwoord te krijgen op enkele interessante vragen. Tijdens het opzetten van het project en het uitvoeren van de data-analyses kon ik bepalen welke voor- en nadelen, die uit de literatuurstudie komen, echt van toepassing zijn. Daarnaast kwam ik ook nieuwe moeilijkheden en sterktes van Elasticsearch tegen die kunnen aansluiten bij het resultaat van de literatuurstudie.

Een voordeel van een project opzetten om bepaalde zaken zelf te gaan ondervinden is dat men de grootte van het voor- of nadeel beter kan inschatten. Als men bijvoorbeeld een zwakte van Elasticsearch ondervind, dan zal men toch een antwoord op de vooraf opgestelde vraag moeten krijgen. Men zal dan ondervinden in hoeverre Elasticsearch toch in staat is om als hulpmiddel te dienen bij het oplossen van de vraag. Of misschien is er workaround waardoor de zwakte eigenlijk niet zo'n groot probleem is. Dat is informatie die met een literatuurstudie moeilijker te verkrijgen is.

\subsection{De dataset}
De dataset heb ik verkregen van het bedrijf waar ik mijn stage doe. Insites Consulting is een consulting bureau die haar klanten ondersteund in het nemen van doorslaggevende beslissingen. Dat doet men aan de hand van marktonderzoek. Uit de resultaten van zo'n marktonderzoek creërt men inzichten die worden doorgegeven aan de klant. 

De ervaring leert dat het soms moeilijk is voor de klant om zo'n inzicht te benutten. In andere gevallen komen de resultaten van het marktonderzoek ergens in een documentje op de computer van de klant en wordt er verder niks mee gedaan. Insites Consulting bouwde enkele jaren geleden een applicatie die dit probleem tegengaat. De applicatie heet Insight Activation Studio. Elke klant krijgt een unieke Studio die aangepast wordt naar de noden, waarden en kleuren van de klant. Die aanpassingen gebeuren in eerste instantie door mensen van Insites Consulting maar ook de klant heeft een dashboard ter beschikking. Een dashboard is een geïsoleerd stuk van de applicatie die admin-gebruikers toelaat om de studio van hun bedrijf te beheren.  

Werknemers van de klant kunnen zich registreren bij de Studio van hun bedrijf. Eens ze aangemeld zijn krijgen ze de mogelijkheid om walls\footnote{Een wall is een verzameling van tiles die min of meer over hetzelfde onderwerp gaan.} en tiles\footnote{Een tile is vergelijkbaar met een post op Facebook maar met meer mogelijkheden. Een tile bestaat uit een type (idee, filmpje, foto, observatie, quiz, discussie, …), een titel, een beschrijving en er kan ook media aan toegevoegd worden. Andere mensen kunnen op jouw tile reageren en kunnen deze ook liken.} aan te maken. Ook krijgen ze walls en tiles van anderen te zien. Het is de bedoeling dat de verworven inzichten op deze Studio komen zodat mensen daarop kunnen reageren en liken. Zo ziet men snel welke inzichten populairder zijn bij de werknemers en worden die tot leven gebracht. Uit die inzichten kunnen ook nieuwe ideën vloeien.

De Insights Academy is een feature die in de Studio verweven zit. Daarop kunnen werknemers lessen volgen om te leren hoe men gebruik kan maken van zo’n inzicht. Daarnaast zijn er nog andere zaken (leaderboards, widgets, teams, … ) die het volledige proces leuker maken. Insights Activation Studio is dus eigenlijk de social media voor werknemers binnen een bedrijf om inzichten te creëren en tot leven te brengen.

De dataset die ik gebruikte in mijn project is de SQL Server dataset van de Insight Activation Studio. Een uitleg van de tabellen wordt telkens gegeven wanneer ze van toepassing zijn. Een script om de dataset te creëren in SQL Server kunt u vinden in Bijlage 1. \textbf{TODO: BIJLAGE 1 toevoegen} Alle namen van personen die in de dataset voorkomen werden willekeurig gegenereerd om anonimiteit te verzekeren.

\subsection{De vragen}
De vragen heb ik verkregen van mijn co-promoter, Ken Vanderbeken, die Lead Developer is aan de Insight Activation Studio. Voor hem is het zeer interessant om te weten of er aspecten zijn die bepalen of een tile succesvol is. Een tile stelt een inzicht voor en een inzicht tot leven brengen is net de primaire doelstelling van de applicatie. Daarom gaan alle vragen daarover. Om te bepalen of een tile succesvol is keek ik hoeveel likes en comments de tile heeft.

De vragen zijn de volgende:
\begin{itemize}
	\item Werken bepaalde tile types beter dan andere? Meer response? (like/comment) 
	\item Waar gebeuren de meeste likes? Vanaf de homepagina of op wall pages?
	\item Heeft de lengte van de titel van een tile invloed op aantal comments/likes? 
\end{itemize}

\subsection{Opzetten van het project}

Voor de installatie van Elasticsearch verwijs ik graag naar sectie \ref{Installatie} uit de literatuurstudie waar de installatie aan bod komt. De installatie gebeurde probleemloos op de manier zoals het daar beschreven staat. Ik maakte geen gebruik van de grafische user interface aangezien het over een eenvoudige installatie gaat.

Om de data te exporteren heb ik gekozen voor een tool die ondersteund wordt door de community: JBDC importer for Elasticsearch. Mijn keuze is niet uitgegaan naar Logstash omdat er in de gids vermeld staat dat Logstash vooral gebruikt wordt om logs op te slaan. Ook had ik geen nood aan alle features die Logstash te bieden heeft. De methode van de JBDC importer leek me in mijn geval veel bruikbaarder.

Ik begon met de JBDC importer versie 2.3.4.1 te downloaden en uit te pakken. De uitgepakte map bevat een modelscript dat slechts een aantal aanpassingen nodig heeft om uitgevoerd te kunnen worden. Het script laat je toe om een query naar uw databank te sturen, en de resultaten op te slaan in één van uw Elasticsearch indices. Daarna downloadde ik de SQL Server JDBC driver versie 6.2 en kopieerde die naar de lib map in de JDBC importer. Deze stap is onnodig indien men met een MySQL databank werkt. 

De voorlaatste stap is het aanmaken van de indices. Een index aanmaken in Elasticsearch is zeer eenvoudig. Via de API moet er een PUT-request worden gestuurd met als URL: http://localhost:9200/naam\textunderscore index.
Per index moet het modelscript, mits een aantal aanpassingen, uitgevoerd worden. Het modelscript is te zien in figuur \ref{fig:data_import}.

\begin{figure}
	\centering
	\includegraphics[width= 15cm]{data_import}
	\caption{Modelscript om data te exporteren van SQL Server naar Elasticsearch}
	\label{fig:data_import}
\end{figure}

\subsection{Uitvoeren van de data-analyses}
Nadat ik de dataset succesvol overzette werd het tijd om met Elasticsearch te leren werken. Een belangrijk voordeel van de zoek- en analyse machine is dat er veel support is. Op hun website bieden ze een zeer uitgebreide, gestructureerde gids aan die alle mogelijkheden van Elasticsearch overloopt. In de gids kan men ook de versie kiezen waarop men werkt. Op die manier blijft de informatie steeds relevant. De gids wordt goed onderhouden wat wil zeggen dat er steeds informatie over de nieuwste versie van Elasticsearch ter beschikking is. 

Ik had geen voorkennis van de taal noch de structuur die gebruikt wordt om de API van Elasticsearch aan te spreken. Waar ik wel een grondige voorkennis van had was de query language van SQL Server. Die voorkennis kwam goed van pas omdat er vanuit de guides van Elasticsearch met regelmaat verwezen wordt naar de query language van SQL Server. Dat vergemakkelijkte mijn leerproces. Je zou kunnen stellen dat gebruikers zonder die voorkennis dan sterk benadeeld worden maar de makers van de gids zorgden ervoor dat je ook zonder die voorkennis de verschillende aspecten van Elasticsearch kunt begrijpen. Kennis van de query language van SQL Server geeft dus een boost aan het leerproces maar is zeker geen verplichting.

Naast de uitstekende gids kan men ook vragen stellen op het forum die toegankelijk is via hun website. Op het forum bieden medewerkers van Elasticsearch of andere mensen hun oplossingen aan voor uw probleem. Het forum kan als een actief forum beschouwd worden met 907 nieuwe posts per maand. Ook op andere bekende forums is Elasticsearch een populair onderwerp. Een zoekopdracht op Stack Overflow geeft bijna 68 000 resultaten die gerelateerd zijn aan Elasticsearch. Uit de literatuurstudie bleek dat er ook veel boeken ter beschikking zijn. Ze worden door velen sterk aangeraden. Toch ben ik op de boeken niet teruggevallen aangezien er online zo'n grote community is. 

Hieronder volgt nogmaals een opsomming van de vragen waarop ik een antwoord zocht via Elasticsearch. Bij elke vraag toon ik aan hoe ik te werk ben gegaan, welke moeilijkheden ik ondervond en welke sterktes van Elasticsearch ik ondervond. Om de API aan te spreken gebruikte ik Postman. Dat is een persoonlijke voorkeur. Elke andere API client zal hiervoor werken.

\subsubsection{Werken bepaalde tile types beter dan andere?}
Om een antwoord op deze vraag te vinden hebben we 2 indices uit de dataset nodig: de tile-index en de tiletype-index. Er bestaat een één op veel relatie tussen tile en tiletype. Een tile houdt steeds het id van zijn tiletype bij. We zullen de tiles eerst moeten groeperen per type waarna we per groep de gemiddelde activiteit berekenen. Uit de resulaten zal blijken of tiles van een bepaalde tiletype meer activiteit vertonen dan andere. De activiteit wordt beschouwd als de som van het aantal likes en het aantal comments.

Elasticsearch biedt een oplossing voor dit probleem. Met aggregaties wordt het mogelijk om documents te groeperen. In de gids over aggregaties wordt de vergelijking gemaakt met het GROUP BY sleutelwoord in SQL Server. Daarbij vermelt men dat aggregaties in Elasticsearch echter veel meer mogelijkheden bieden. Zo bestaan er een 50-tal soorten aggregaties. Dat is een groot aantal die het gebruik ervan complex maakt. Zeker omdat aggregaties ook genest kunnen worden. Dat wil zeggen dat men binnen een aggregatie opnieuw een aggregatie kan doen. De flexibiliteit is echter zeer hoog omdat de mogelijkheden enorm zijn. Mijn ervaringen tot nu toe spreken dus tegen met \textbf{TODO: BRON} waarin verteld wordt dat Elasticsearch minder flexibiliteit biedt dan SQL Server. Bij het oplossen van de volgende vraag kom ik hier op terug. \textbf{TODO: BEN JE HIEROP TERUGGEKOMEN?}

Om alle tiles uit de tile-index op te vragen moeten we een GET request sturen naar Elasticsearch. Om verdere filteringen, sorteringen of andere functies uit te voeren zijn er 2 methodes. Bij de eerste methode kan men parameters meegeven op het einde van de URL. Bij de tweede methode kan men een body in JSON-formaat meegeven aan de call. Ik koos voor de tweede methode omdat niet alle mogelijkheden binnen Elasticsearch meegegeven kunnen worden aan de URL. Bij deze keuze struikelde ik meteen op een eerste probleem. Niet alle API clients, inclusief Postman, bieden de mogelijkheid om een body mee te geven aan een GET call omdat dat geen normale manier van werken is. De ontwikkelaars van Elasticsearch hebben daar rekening mee gehouden en zorgden ervoor dat data opvragen ook met een POST request mogelijk is. Ik verloor niet meer dan 5 minuten aan dit probleem en aangezien er een kleine workaround is beschouw ik het niet als een nadeel.

De URL van de call ziet er als volgt uit: http://localhost:9200/tile/\textunderscore search. Het woord tile duidt aan dat we binnen de tile-index zoeken. Het woord \textunderscore search geeft aan dat we naar documents binnen de index zoeken. Indien we dat laatste niet meegeven krijg je enkel het schema van de index terug.

De body is te zien in figuur \ref{fig:script1}. De eerste parameter in de body is size. Size geeft aan hoeveel documenten er zichtbaar moeten zijn in het resultaat. Je zou het kunnen vergelijken met SELECT TOP X in SQL Server. Aggregaties worden telkens onder alle documents getoond. Aangezien we enkel interesse hebben in de aggregaties kiezen we een size van 0 zodat er geen documents zichtbaar zijn. De tweede parameter is de aggregatie. We maken een aggregatie en noemen die group\textunderscore by \textunderscore tileTypeId. In de terms parameter van onze aggregatie geven we aan dat we op het veld tileTypeId willen groeperen. Daarna geven we een nieuwe aggregatie mee aan group\textunderscore by \textunderscore tileTypeId. We noemen de aggregatie avg\textunderscore response. We geven aan dat die aggregatie een gemiddelde moet berekenen. In het script wordt meegegeven van welke waarde het gemiddelde moet worden genomen. We willen het gemiddelde van de som van het aantal comments en het aantal likes en geven dat ook op die manier mee.

\begin{figure}
	\centering
	\includegraphics{script1}
	\caption{Body script 1}
	\label{fig:script1}
\end{figure}

Als we het script uitvoeren krijgen we een resultaat zoals te zien in figuur \ref{fig:scriptresult1}. Elk resultaat begint met wat algemene informatie zoals: hoeveel tijd de query nodig had, hoeveel shards er succesvol overlopen zijn, hoeveel shards faalden, hoeveel documents er voldoen aan de zoekopdracht, etc. In figuur \ref{fig:scriptresult1} is echter enkel het deel te zien dat op dit moment interessant is, namelijk de resultaten van de aggregaties.

\begin{figure}
	\centering
	\includegraphics{scriptresult1}
	\caption{Resultaat script 1}
	\label{fig:scriptresult1}
\end{figure}

Het key-veld in de resultaten stelt telkens het tiletypeid voor waarop we groepeerden. Per aggregatie werd er een nieuwe aggregatie uitgevoerd die de gemiddelde activiteit berekende. De gemiddelde activiteit valt af te lezen in het value-veld. Het is duidelijk dat, in deze dataset, tiles met tiletypeid 2 meer activiteit vertonen dan andere tiles. Dat is leuk om te weten maar zegt op zich niet veel. We willen graag weten met welk tiletype deze id overeen komt. We stoten echter op een probleem.

Om een zoekopdracht uit te voeren op meerdere indices tegelijk zouden we de indeces bij bepaalde voorwaarden moeten samenvoegen. In SQL Server kan men dit realiseren met het JOIN-sleutelwoord. Join-operaties zijn zeer duur in Elasticsearch. Zo duur dat de ontwikkelaars ervoor zorgden dat join-operaties over verschillende indices onmogelijk zijn. Een document moet alle informatie bevatten die nodig is om te beslissen of het al dan niet in de zoekresultaten terechtkomt. Je moet dus op voorhand beslissen hoe je gaat zoeken en uw index daaraan aanpassen. Indien de query herhaaldelijk moet worden uitgevoerd is dat de moeite waard en vormt dat geen probleem. Maar in ons geval willen we een éénmalig antwoord op onze vraag. Dat wil zeggen dat we telkens een nieuwe index moet aanmaken en de data opnieuw importeren om er nadien slecht één query op uit te voeren. Die manier van werken zorgt voor een index overhead en beschouw ik als een groot nadeel van Elasticsearch.

Bij deze vraag zijn we echter enkel geïnteresseerd in één tiletype. Wat we ook kunnen doen is een tweede query uitvoeren op de tiletype-index. We geven het id mee en vragen zo het juiste tiletype op. Deze manier van werken heeft als voordeel dat we geen nieuwe index moeten aanmaken. De nadelen van deze manier van werken zijn dat je telkens meerdere queries moet uitvoeren en dat het niet altijd realistisch is om dat te doen. Wanneer we over tientallen documenten spreken dan gaat de voorkeur toch naar het aanmaken van een nieuwe index. Voor ons is dat niet van toepassing dus koos ik voor de tweede methode.

We maken een tweede query met URL: http://localhost:9200/tiletype/\textunderscore search. De body van de query is te zien in figuur \ref{fig:script2}. Er wordt simpelweg gezocht naar een document met id 2. In het resultaat (figuur \ref{fig:scriptresult2}) zien we dat we spreken over een tiletype idea.

Het antwoord op de eerste vraag luidt: Ja, tiles met tiletype idea werken beter dan andere.

\begin{figure}
	\centering
	\includegraphics{script2}
	\caption{Body script 2}
	\label{fig:script2}
\end{figure}

\begin{figure}
	\centering
	\includegraphics{scriptresult2}
	\caption{Resultaat script 2}
	\label{fig:scriptresult2}
\end{figure}

\subsubsection{Waar gebeuren de meeste likes? Vanaf de homepagina of op wall pages?}
Om deze vraag te beantwoorden hebben we 3 indices nodig: like, log en logtype. Wanneer een gebruiker naar de homepagina navigeert dan wordt dat gelogd in de log-tabel met logtype 8. Wanneer een gebruiker naar een wall page navigeert dan wordt dat gelogd in de log-tabel met logtype 10. Wanneer een gebruiker een tile liked dan komt er een nieuw record in de like tabel. Bij dit probleem zullen we wel verplicht zijn om een nieuwe index aan te maken. We willen namelijk 3 tabellen samennemen en we zijn geïntereseerd in alle documents.

In onze nieuwe index hebben we slechts twee velden nodig: de id van de like en de pagina waarop de like gebeurde. Er zal een script moeten geschreven worden om de data van SQL Server naar de nieuwe index te exporteren. In het script moet, per like, uitgemaakt worden of die vanop de homepagina of vanop een wall pagina gebeurde. We willen dus de meest recente log met logtype 8 of 10 die minder recent is dan de like en dezelfde userId heeft als de gebruiker die de like uitvoerde. Het SQL-script is te zien in figuur \ref{fig:script3}. Het valt op dat sommige likes dubbel voorkomen in de index. De oorzak hiervan is dat de tijd waarop een log aangemaakt wordt, telkens afgerond is op één minuut. Als men binnen de minuut beide pagina's bezoekt en vervolgens een tile liked is het niet duidelijk vanop welke pagina de like gebeurde. Omdat het hier om een zeer klein aantal dubbele likes gaat worden deze gewoon meegeteld op beide pagina's.

\begin{figure}
	\centering
	\includegraphics[width=17.5cm]{script3}
	\caption{SQL-script voor het importeren van de data uit vraag 2}
	\label{fig:script3}
\end{figure}

De index staat klaar en nu moeten we enkel nog een aggregatie doen op de plaats waar er geliked werd. De URL van de query ziet er als volgt uit: http://localhost:9200/question2/\textunderscore search. In de body (figuur \ref{fig:script4}) geven we mee dat we een aggregatie willen op het liked\textunderscore from-veld. Aan de hand van die aggregatie kunnen we zien hoeveel likes er op de homepagina gebeurden en hoeveel likes er op wall pages gebeurden. Het resultaat van de query is te zien in figuur \ref{fig:scriptresult4}.

\begin{figure}
	\centering
	\includegraphics{script4}
	\caption{Body script 4}
	\label{fig:script4}
\end{figure}

\begin{figure}
	\centering
	\includegraphics{scriptresult4}
	\caption{Resultaat script 4}
	\label{fig:scriptresult4}
\end{figure}

Uit het resultaat kunnen we besluiten dat de meeste likes vanaf de homepagina gebeuren. Dat is dan ook meteen het antwoord op de vraag. Men kan echter wel zien dat het aantal likes vanaf de homepagina en het aantal likes vanaf wall pages zeer dicht bij elkaar liggen. 

Bij het oplossen van deze vraag zou het onbegonnen werk zijn geweest om meerdere queries uit te voeren op verschillende indices. De werkwijze die in de vorige vraag de voorkeur kreeg kon hier niet worden herbruikt. Het meest complexe rekenwerk was het bepalen vanop welke pagina een like gebeurde. Elasticsearch biedt geen eenvoudige manier om die berekening te doen. Het gebrek aan joins werd nu ervaren als een groot nadeel.

\subsubsection{Heeft de lengte van de titel van een tile invloed op aantal comments/likes}

Om te bepalen of er een verband is tussen de variabelen lengte van de titel en aantal comments/likes zullen we een chi-kwadraat toets uitvoeren. Indien uit het resultaat blijkt dat er een verband is kan de sterkte van het verband berekend worden met Cramers V. Elasticsearch biedt geen ondersteuning voor dergelijke berekeningen. Deze kunnen nochtans zeer interessant zijn bij het maken van een data-analyse. Om toch een antwoord op de vraag te krijgen zullen we Elasticsearch als hulpmiddel gebruiken bij het uitvoeren van de chi-kwadraattoets. Op die manier zal het duidelijk worden in hoeverre Elasticsearch ons kan helpen bij ingewikkelde calculaties zoals de chi-kwadraat toets. 

De eerste stap bij het uitvoeren van een chi-kwadraat toets is het opstellen van een kruistabel. Bij het opstellen van een kruistabel moeten we onze variabelen indelen in klassen. We berekenen per variabele de grootste waarde in de dataset zodat we weten tot hoever onze klassen moeten reiken. Figuur \ref{fig:calculatenamelength} toont hoe we de lengte van de langste naam van een tile kunnen berekenen. Bij het uitvoeren van deze query krijgt men en resultaat van 49. In een gelijkaardige query vinden we dat de maximale som van het aantal likes en het aantal comments van een tile 33 is.

We kiezen ervoor om beide variabelen op te delen in drie klassen. Voor de variabele lengte van de titel stellen de klassen [0, 17], [18, 34] en [35, 51] respectievelijk 'korte titel', 'middellange titel' en 'lange titel' voor. Voor de variabele aantal comments/likes stellen de klassen [0, 11], [12, 22] en [23, 33] respectievelijk 'weinig activiteit', 'gemiddelde activiteit' en 'veel activiteit' voor. We kunnen nu onze kruistabel opstellen.

\begin{figure}
	\centering
	\includegraphics{calculate_name_length}
	\caption{Body om de lengte van de langste naaam van een tile te berekenen}
	\label{fig:calculatenamelength}
\end{figure}

Er kan een query geschreven worden in Elasticsearch die de waarden voor onze kruistabel teruggeeft. De aggregatie die aangemaakt word is terug te vinden in bijlage 2. \textbf{TODO: voeg bijlage 2 toe} We noemen de aggregatie table. In het filter-veld geven we '1=1' mee om te forceren dat alle documents in de resultaten terugkomen. Het filter-veld zou hier als overbodig kunnen worden beschouwd maar het weglaten ervan zorgt voor foutmeldingen. In onze table-aggregatie maken we drie nieuwe aggregaties aan. Elk van de aggregaties stelt een klasse van de lengte van de titel voor. We noemen de aggregaties row0-17, row18-35 en row35, 51. In het filter-veld van elk van deze aggregaties geven we mee dat enkel documents die tot die klasse behoren mogen meegeteld worden in de resultaten. We doen dit door restricties op te leggen op de lengte van de titel van de tile. In elk van de drie aggregaties maken we opnieuw drie aggregaties aan die de klassen van het aantal comments/likes voorstellen. Opnieuw geven we restricties mee in elk van de filter-velden zodat de juiste documents in de juiste klassen komen. Het resultaat van de query wordt weergegeven in bijlage 3 \textbf{TODO: voeg bijlage 3 toe}. In figuur \ref{fig:tablewrong} worden de resultaten in een kruistabel weergegeven.

De tweede stap houdt in er voor elke waarde in de kruistabel een verwachte waarde moet berekend worden. De verwachte waarde wordt berekend door het totaal van de rij te vermenigvuldigen met het totaal van de kolom en dat resultaat te delen door de echte waarde. De verwachte resultaten komen opnieuw in een kruistabel (figuur \ref{fig:tablewrongV}).

In de derde stap wordt er gevalideerd of de verwachte waarden voldoen aan de stelling van Cochran. De stelling van Cochran luidt dat geen enkele cel een verwachte waarde kleiner dan 1 mag hebben. Daarnaast mag niet meer dan 20\% van de cellen een verwachte waarde kleiner dan 5 hebben. Indien de kruistabel niet voldoet aan de stelling van Cochran dan heeft de uitkomst van de chi-kwadraat toets geen betekenis. We valideren onze kruistabel aan de stelling van Cochran en besluiten dat meer dan 20\% van de cellen een verwachte waarde kleiner dan 5 heeft. Om de chi-kwadraat toets toch te kunnen uitvoeren zullen de klassen moeten opnieuw ingedeeld moeten worden. We behouden de klassen van de lengte van de titel. De nieuwe klassen [0, 16] en [17, 33] stellen respectievelijk 'weinig activiteit' en 'veel activiteit' voor. We passen onze query aan om de waarden voor de kruistabel te berekenen. De nieuwe query is terug te vinden in bijlage 3 \textbf{TODO: voeg bijlage 3 toe}. In figuur \ref{fig:tablecorrect} worden de resultaten in een kruistabel weergegeven.


\begin{figure}
	\centering
	\includegraphics{table_wrong}
	\caption{Kruistabel voor vraag 3}
	\label{fig:tablewrong}
\end{figure}

\begin{figure}
	\centering
	\includegraphics{table_wrong_V}
	\caption{Verwachte waarden voor vraag 3}
	\label{fig:tablewrongV}
\end{figure}

\begin{figure}
	\centering
	\includegraphics{table_correct}
	\caption{Kruistabel voor vraag 3 na de herindeling van de klassen}
	\label{fig:tablecorrect}
\end{figure}

We berekenen opnieuw de verwachte waarden (figuur \ref{fig:tablecorrectV}) en valideren onze kruistabel opnieuw aan de stelling van Cochran. Alle cellen hebben een verwachte waarde groter of gelijk aan 1. Slechts 1/6 (16,667\%) van de cellen hebben een verwachte waarde die kleiner is dan 5. Deze keer wordt er voldaan aan de stelling van Cochran. Het resultaat van de chi-kwadraattoets zal nu wel betekenisvol zijn.


\begin{figure}
	\centering
	\includegraphics{table_correct_V}
	\caption{Verwachte waarden voor vraag 3 na de herindeling van de klassen}
	\label{fig:tablecorrectV}
\end{figure}

In de vierde en laatste stap bereken we de waarde voor $\tilde\chi^2$ (chi-kwadraat). Deze waarde kunnen we vergelijken met de kritieke waarde om te bepalen of er samenhang is tussen de twee variabelen. $\tilde\chi^2$ is de som van de kwadraten van het verschil van de werkelijke waarde en de verwachte waarde gedeeld door de verwachte waarde. In een laatste kruistabel (figuur \ref{fig:table_correct_values}) kunnen we deze waarde voor elke cel terugvinden.

\begin{figure}
	\centering
	\includegraphics{table_correct_values}
	\caption{Verwachte waarden voor vraag 3 na de herindeling van de klassen}
	\label{fig:tablecorrectvalues}
\end{figure}

De som van al deze waarden, en daarmee ook $\tilde\chi^2$, is 1,7412. We werken met een significantieniveau van 5\%. Om de kritieke waarde op te zoeken hebben we het aantal vrijheidsgraden (df) nodig. Het aantal vrijheidsgraden bereken je door het aantal rijen - 1 te vermenigvuldigen met het aantal kolommen -1. In dit geval is dat 2 keer 1. De kritieke waarde voor 2 vrijheidsgraden met significantieniveau 5\% is 5,99. De berekende $\tilde\chi^2$ is strikt kleiner dan 5,99 wat wil zeggen dat er geen verband is tussen de twee variabelen.

