%%=============================================================================
%% Inleiding
%%=============================================================================

\chapter{Inleiding}
\label{ch:inleiding}

\section{Stand van zaken}
\label{sec:stand-van-zaken}

Elasticsearch is een zoekmachine die in Java geschreven is. De zoekmachine werd boven de Java library Apache Lucene gebouwd. Alle commando's worden verzonden door middel van HTTP requests naar de Elasticsearch REST API. Die API is gebaseerd op JSON. Dat wil zeggen dat de mogelijkheid bestaat om JSON mee te geven aan de HTTP requests. Ook de resultaten worden in JSON teruggegeven. Elasticsearch is niet enkel een zoekmachine maar wordt ook gebruikt voor data-analyses en om aan logging te doen. 

Shay Bannon ontwierp Elasticsearch als een gedistribueerd systeem. Een gedistribueerd systeem brengt zowel voordelen als nadelen met zich mee. Volgens \textcite{Brasetvik2013} focussen verschillende systemen op verschillende sterktes, afhankelijk van welke eigenschappen belangrijker zijn voor het systeem. Daarbij wordt gezegd dat Elasticsearch focust op snelheid. Het streeft naar real-time search. Om dat de kunnen bereiken in een gedistribueerd systeem worden een aantal zaken aan de kant geschoven of vereenvoudigd. Een voorbeeld hiervan is concurrency control. Die wordt gedaan aan de hand van versienummers van de documents. Dit is wat we noemen een optimistische aanpak. Deze manier van werken zorgt ervoor dat het systeem zich niet moet bezighouden met locks. Met locks bedoelt men dat, wanneer een transactie aan het schrijven is, niemand anders naar dezelfde tabel kan schrijven totdat de transactie is voltooid. Er wordt namelijk een slot geplaatst op te tabel zolang deze bezet is. Het is duidelijk dat het werken met versienummers minder complexiteit met zich meebrengt dan het werken met locks. Daarom is de optimistische concurrency control performanter. Dat is echter enkel zo in een systeem waar de data niet veel aangepast wordt. Wanneer de data wel frequent aangepast wordt kan het zijn dat de optimistische aanpak juist minder performant wordt dan de pessimistische aanpak met de locks. Wanneer het systeem bij de validatie op het versienummer merkt dat de data veranderd is, moet de gehele transactie namelijk opnieuw gestart worden. De bedoeling van de optimistische aanpak is dat men over real-time search kan spreken. Wanneer men in een omgeving werkt met data die frequent verandert moet men rekening houden dat men de eigenschappen van real-time search kan verliezen. Een tweede manier om aan snelheid te winnen in een gedistribueerd systeem is caching. Elasticsearch doet vaak aan caching om niet telkens opnieuw alle data te moeten opvragen. Dat heeft een negatief effect op het geheugen dat het systeem nodig heeft maar ook een zeer positief effect op de uitvoeringstijd.

Het CAP theorema stelt dat het onmogelijk is voor een gedistribueerd systeem om gelijktijdig consistent (Consistent), beschikbaar (Available) en partitie tolerant (Partition tolerant) te zijn. Het stelt dat een gedistribueerd systeem tegelijk aan maximaal twee van de voornoemde eigenschappen kan voldoen. Consistent betekent dat alle nodes in de cluster dezelfde data zien op hetzelfde moment. Daarbij is het belangrijk dat deze data de meest recente data is. Men kan spreken over een beschikbaar systeem wanneer alle nodes een reponse kunnen geven voor alle requests. Wanneer een node geen response kan geven op een request wordt er niet aan de criteria voldaan om over een beschikbaar systeem te kunnen spreken. De laatste voorwaarde in het CAP theorema, partitie tolerant, houdt in dat het systeem correct blijft functioneren bij het uitvallen van een node in het netwerk. Volgens \textcite{Brasetvik2013} is het bij Elasticsearch over het algemeen zo dat het systeem consistent en partitie tolerant is. Dat noemt men een CP-systeem. Hierbij is het niet onbelangrijk om te vermelden dat er een zwakke definitie voor consistentie gebruikt wordt. Wat er precies gegarandeerd wordt is namelijk document consistentie waarbij er sprake is van consistentie binnen een document. Wanneer men Elasticsearch enkel gebruikt om data uit te lezen bereikt men een systeem dat beschikbaar en partitie tolerant is. Dat noemt men een AP-systeem.

\textcite{Glauner2012} schrijft dat één van de belangrijkste sterktes van de zoekmachine is dat het gebruik maakt van een schema-less data model. Hierdoor kan elk JSON document aan Elasticsearch toegevoegd worden. Dat zorgt voor veel flexibiliteit en minder configuratiewerk voor de gebruikers. \textcite{Brasetvik2013} gebruikt liever de term schema flexible. Er is namelijk wel een schema, alleen moet dat niet verplicht meegegeven worden. De zoekmachine is zeer sterk in het herkennen van eenvoudige datatypes zoals nummers, booleans en timestamps. Daardoor kan het schema gegenereerd worden zonder expliciet te moeten meegeven wat de datatypes zijn. De mogelijkheid om een schema mee te geven bestaat echter wel. Een reden om zelf een schema mee te geven is om de data op punt te stellen en zo de zoeksnelheden te doen laten stijgen.  \textbf{Hier zou ik ook nog iets kort vermelden dat er altijd zoiets is als een impliciet schema: als je alle mogelijke data in je databank steekt zonder dezelfde structuur, dan ga je ze niet kunnen bevragen.}

\subsection{Elasticsearch archeologie}

Om dit onderzoek beter te begrijpen worden de belangrijkste termen uit het domein van Elasticsearch eerst kort besproken. In het boek van \textcite{Dixit2016} leert men hoe de achterliggende structuur van Elasticsearch in elkaar zit. Elasticsearch bestaat uit een cluster. De eerste cluster heeft standaard Elasticsearch als naam. Alle clusters samen stellen de data voor. In figuur \ref{fig:ESArchitecture} van \textcite{Babaev2013} is te zien hoe zo'n cluster in elkaar zit. Een node is een instantie van Elasticsearch. Bij de creatie krijgt een node standaard een UUID en komt bij de Elasticsearch cluster tenzij anders gedefinieerd. In de nodes zitten de indices. Een index is een verzameling van documents met gelijkaardige karakteristieken. Hier slaat Elasticsearch data in op. Een index kan zeer groot worden. Het kan gebeuren dat de index te groot wordt om op de schijf van een node op te slaan. Daarom bestaat een index uit meerdere shards en replicas. Deze worden door Elasticsearch voorzien om een index op te delen in stukken. Een shard kan een primaire shard of een secundaire shard zijn. Operaties die data aanpassen gebeuren op primaire shards. Secundaire shards bevatten kopies van de data van de primaire shards en zorgen ervoor dat het zoeken snel gebeurt. Kopies van data bewaren heeft ook als effect dat er sprake is van een hoge beschikbaarheid. Wanneer een primaire shard wordt stopgezet valt een secundaire shard in om de rol van de primaire shard te vervangen. Een veelgebruikt synoniem voor een secundaire shard is replica. Als laatste zijn er documents. Een document is een JSON object dat de key-value paren bevat van één object.

\begin{figure}
	\centering
	\includegraphics[width= 10cm]{ESArchitecture}
	\caption{Een cluster in Elasticsearch}
	\label{fig:ESArchitecture}
\end{figure}

\subsection{Schaalbaarheid}

Bij Elasticsearch is er sprake van horizontale schaalbaarheid \autocite{Dixit2016}. Dat wil zeggen dat een cluster opgedeeld wordt in verschillende nodes. De nodes kunnen zonder problemen op verschillende hardware functioneren. Een cluster kan dus uitgebreid worden zonder dat de complexiteit van het systeem toeneemt. Bij het toevoegen van een nieuwe node worden de shards verplaatst zodat de nodige opslagruimte minimaal blijft.

In de master thesis van \textcite{Berglund2013} wordt er een belangrijke stelling gemaakt over de schaalbaarheid van Elasticsearch. De search engine is zeer schaalbaar omdat de documents organisatorisch verdeeld zijn over verschillende nodes. Bij een specifieke zoekopdracht waarbij men zoekt op het document ID of het type zullen slechts enkele nodes moeten overlopen worden. Dat ideale scenario is echter niet altijd aan de orde. Afhankelijk van de criteria waarop men zoekt, kan het zijn dat alle nodes moeten overlopen worden. Dat is een limitatie van de schaalbaarheid van Elasticsearch. Dat probleem zou vandaag nog niet opgelost kunnen worden zonder dat er data-verlies voorkomt in de zoekresultaten. 

\subsection{Installatie}
\label{Installatie}

Elasticsearch is gratis wanneer men beslist om het zelf te hosten. De installatie verloopt zeer snel. Eerst moet men ervoor zorgen dat Java geïnstalleerd staat op het systeem. Daarna kan er een versie naar keuze van Elasticsearch gedownload worden via de website. Wanneer men het bestand uitpakt staat alles klaar om de eerste cluster op te starten. Als dat te moeilijk is kan men gebruik maken van een grafische user interface die beschikbaar is via de MSI installer package. Op de website staat stap voor stap uitgelegd hoe je de installatie kunt uitvoeren. 

Er hangen niet zoveel nadelen vast aan het zelf hosten van Elasticsearch. Men moet natuurlijk wel over voldoende ruimte beschikken op de harde schijf. Dat kan moeilijk worden wanneer men met grote hoeveelheden data werkt. Daarnaast is het belangrijk om te weten dat men zelf verantwoordelijk bent voor eventuele downtimes. Het is dus perfect mogelijk om Elasticsearch volledig gratis te gebruiken. 

Wanneer men beslist om te betalen voor de hosting bij Elasticsearch beschikt men wel over enkele voordelen. De eerder vermelde problemen in verband met ruimte op je harde schijf en downtimes zijn niet langer van toepassing. Aan de externe hosting zijn er een aantal Service Level Agreements verbonden die ervoor zorgen dat men verzekerd is van een goede kwaliteit en dat men kan rekenen op voldoende support. De kostprijs begint met 36,53 EUR per maand. Er is ook een mogelijkheid om eerst een proefversie van 14 dagen te gebruiken.

\subsection{Data importeren in Elasticsearch}

Om data te exporteren van de databank naar Elasticsearch zijn er een aantal mogelijkheden, afhankelijk van welke databank er gebruikt wordt. De eerste mogelijkheid is er één die Elasticsearch zelf aanbiedt. Daarvoor maken ze gebruik van een ander product uit de Elastic Stack\footnote{De Elastic Stack is een verzameling van open-source producten van Elastic.}: Logstash. Logstash is een ETL-tool om data te verwerken, te transformeren en uit te wisselen. Het is een product waar veel informatie en support over te vinden is. Logstash is dus een tool die veel flexibiliteit biedt maar wel een extra installatie vergt. 

Daarnaast zijn er een aantal tools die aangeboden worden door de community. Voor die tools is er in het algemeen minder support te vinden. Nog een nadeel is dat het niet altijd mogelijk is om de data naar de laatste versie van Elasticsearch te exporteren. De versies van de tools lopen namelijk in het algemeen achter op de nieuwste versie van Elasticsearch. 

Zowel Logstash als de meeste tools die worden aangeboden door de community bieden ook de functionaliteit aan om data te synchroniseren. Dat wil zeggen dat, wanneer de data verandert in de databank, die veranderingen ook doorgevoerd worden in Elasticsearch. In veel use cases zal dit veel voordelen bieden. 

\subsection{Support}

Ook support is een zeer belangrijk aspect wanneer men overweegt om met Elasticsearch te werken. Een eerste onderdeel van support is de documentatie. Hoeveel informatie kan men vinden over de werking van Elasticsearch? Volgens \textcite{Glauner2012} was die documentatie in 2012 onvoldoende. Uit het project in hoofdstuk 3 zal blijken dat deze documentatie echter zeer uitgebreid geworden is. Ook staat er een grote community achter Elasticsearch die zeer bruikbare features aanbiedt. Verder zijn er talrijke boeken te vinden (\textcite{Turner}). Deze boeken reiken van boeken waar beginners mee aan de slag kunnen tot boeken waarmee experten hun kennis verder kunnen uitbreiden.

\subsection{Gebruik van Elasticsearch}

Elasticsearch wordt door veel bedrijven momenteel gebruikt voor verschillende doeleinden. Die doeleinden kunnen gaan van logging tot het bestrijden van cyberaanvallen. Enkele opvallende gebruikers van Elasticsearch zijn NASA, Netflix, Github, Facebook, Cisco, Microsoft en Adobe. Deze zijn te vinden op de website van Elasticsearch.

Er kan met de REST API van Elasticsearch gecommuniceerd worden met behulp van elke web client die men prefereert. Men kan er zelf voor kiezen om deze tussenlaag over te slaan door de command line te gebruiken. Elasticsearch voorziet enkele clients die kunnen gebruikt worden in verschillende talen. Veelgebruikte talen zijn Curl, Java, C\#, Python, JavaScript, PHP, Perl en Ruby. Daarnaast biedt ook de community een uitgebreide waaier aan clients.

Elasticsearch biedt veel features zoals full text-search, completion suggesters, custom document scoring en meer. Bij full text-search geeft de gebruiker één of meerdere sleutelwoorden mee. Elasticsearch zal dan zoeken naar documents die de sleutelwoorden bevatten. Bij completion suggesters wordt opnieuw een sleutelwoord meegegeven door de gebruiker. Elasticsearch zal een lijst teruggeven met een aantal voorstellen van relevante sleutelwoorden die de gebruiker dan kan gebruiken om zijn zoektocht verder te zetten. Custom document scoring houdt in dat men zelf een functie kan meegeven die de relevantie van de zoekopdracht berekent. Variabelen die bijvoorbeeld een belangrijke rol kunnen spelen zijn de lengte van het veld, het aantal overeenkomsten en meer. Een uitgebreid aanbod aan features zorgt ervoor dat er meer kans is dat Elasticsearch aan de eisen van de use case voldoet. 

Van authorizatie is er echter geen sprake. Iedere gebruiker van Elasticsearch heeft alle rechten \autocite{Brasetvik2013}. Wanneer men bijvoorbeeld met een team van ontwikkelaars werkt moet daar rekening mee gehouden worden.

\subsection{Alternatieven}

Er zijn heel wat alternatieven voor Elasticsearch op de markt. De meeste alternatieven bieden echter enkel functionaliteiten om data-analyses uit te voeren, om aan logging te doen of om een zoekfunctionaliteit te implementeren. Alternatieven die alle features van Elasticsearch kunnen vervangen zijn dus veel schaarser. 

Een eerste alternatief is Algolia. Algolia is een duurder product dat zich meer op de zoekfunctionaliteit focust. Een groot verschil met Elasticsearh is de security. In tegenstelling tot Elasticsearch bestaat er in Algolia de mogelijkheid om gebruikersrechten in te voeren \autocite{Algolia}. Zo kunnen bepaalde luiken van het product afgeschermd worden voor gebruikers die daar geen toegang mogen toe hebben. Die authorizatie wordt gedaan aan de hand van API keys. Verder zal Algolia het zoekgedrag gaan analyseren zonder dat daar extra configuraties aan te pas gaan. Dat zoekgedrag kan, afhankelijk van de use case, zeer interessante informatie opleveren. Evenals Elasticsearch biedt Algolia ook logging aan. Deze functionaliteit is echter meer uitgebreid in Elasticsearch dan in Algolia. Ook de grote waaier aan aggregaties is niet aanwezig in Algolia. Data-analyses worden dus beter in Elasticsearch gedaan terwijl Algolia meer hulp kan bieden bij zoekfunctionaliteiten.

Een tweede alternatief is Apache Solr. Aapche Solr is zeer vergelijkbaar met Elasticsearch. Elasticsearch biedt meer features terwijl Apache Solr meer fout tolerant is \autocite{Solr}. Voor een eenvoudige maar robuuste zoekfunctionaliteit wordt Apache Solr aangeraden. Voor meer flexibiliteit wordt Elasticsearch aangeraden.

\section{Probleemstelling en Onderzoeksvragen}
\label{sec:onderzoeksvragen}

%% TODO:
%% Uit je probleemstelling moet duidelijk zijn dat je onderzoek een meerwaarde
%% heeft voor een concrete doelgroep (bv. een bedrijf).
%%
%% Wees zo concreet mogelijk bij het formuleren van je
%% onderzoeksvra(a)g(en). Een onderzoeksvraag is trouwens iets waar nog
%% niemand op dit moment een antwoord heeft (voor zover je kan nagaan).

De laatste dertig jaar is data zeer belangrijk geworden voor bedrijven. Ze beschikken over steeds meer data en zoeken naar nieuwe manieren om daar gebruik van te maken. Zo nemen ze belangrijke beslissingen of trekken ze conclusies aan de hand van data-analyses. Een eerste beslissing die moet gemaakt worden bij het uitvoeren van data-analyses is welke tool er zal worden gebruikt. Dat is geen gemakkelijke, maar uiterst belangrijke keuze. Er zijn veel tools beschikbaar en ze hebben allemaal andere sterktes. Omdat die keuze afhankelijk is van de use case waarvoor het zal gebruikt worden bestaat er geen universeel antwoord op dit probleem. Men kan zich enkel baseren op subjectieve meningen van anderen of op beweringen van de ontwikkelaars van de tool. Het hoofddoel van dit onderzoek is om ondersteuning te bieden bij deze keuze. In veel van die gevallen wordt Elasticsearch overwogen. Daarom worden de voor- en nadelen van de zoekmachine onderzocht. Door dit onderzoek wordt het duidelijk welke vragen men zich moet stellen bij het kiezen voor Elasticsearch. Ook de ontwikkelaars van Elasticsearch kunnen met deze voor- en nadelen rekening houden in toekomstige updates.

\section{Opzet van deze bachelorproef}
\label{sec:opzet-bachelorproef}

%% TODO: Het is gebruikelijk aan het einde van de inleiding een overzicht te
%% geven van de opbouw van de rest van de tekst. Deze sectie bevat al een aanzet
%% die je kan aanvullen/aanpassen in functie van je eigen tekst.

De rest van deze bachelorproef is als volgt opgebouwd:

In Hoofdstuk~\ref{ch:methodologie} wordt het project dat werd uitgevoerd in Elasticsearch om voor- en nadelen te introduceren, bevestigen of ontkrachten beschreven.

In Hoofdstuk~\ref{ch:conclusie}, tenslotte, wordt de conclusie gegeven en een antwoord geformuleerd op de onderzoeksvraag. Daarbij wordt ook een aanzet gegeven voor toekomstig onderzoek binnen dit domein.

