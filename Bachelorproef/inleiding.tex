%%=============================================================================
%% Inleiding
%%=============================================================================

\chapter{Inleiding}
\label{ch:inleiding}

\section{Stand van zaken}
\label{sec:stand-van-zaken}

Elasticsearch is een zoekmachine die in Java geschreven is. De initiële release werd uitgebracht in 2010. De zoekmachine werd boven Java library Apache Lucene gebouwd. Alle commando's worden verzonden door middel van HTTP requests naar de Elasticsearch REST API. Die API is gebaseerd op JSON. Dat wil zeggen dat de mogelijkheid bestaat om JSON mee te geven aan de HTTP requests. Ook de resultaten worden in JSON teruggegeven. Elasticsearch is niet enkel een zoekmachine maar wordt ook gebruikt voor data-analyses en om aan logging te doen.

Shay Banon, de oprichter van Elasticsearch, is een zeer goede software ontwikkelaar en een expert in gedistribueerde systemen. De beslissing om een systeem zoals Elasticsearch te maken kwam voort uit zijn frustratie dat er geen goed, gedistribueerd systeem bestond die de functie van een zoekmachine kon invullen en daarnaast ook nog eens open source was. Hij wou eindgebruikers de kans geven om antwoorden te kunnen krijgen uit hun data in een mum van tijd. Dat noemt hij het ultieme doel van Elasticsearch.

Shay Banon ontwierp Elasticsearch als een gedistribueerd systeem. Een gedistribueerd systeem brengt zowel voordelen als nadelen met zich mee. Volgens \textcite{Brasetvik2013} focussen verschillende systemen op verschillende sterktes, afhankelijk van welke eigenschappen belangrijker zijn voor het systeem. Daarbij wordt gezegd dat Elasticsearch focust op snelheid. Het streeft naar real-time search. Om dat de kunnen bereiken in een gedistribueerd systeem worden een aantal zaken aan de kant geschoven of vereenvoudigd. Een voorbeeld hiervan is concurrency control. Die wordt gedaan aan de hand van versienummers van de documents. Dit is wat we noemen een optimistische aanpak. Deze manier van werken zorgt ervoor dat het systeem zich niet moet bezighouden met locks. Met locks bedoelt men dat, wanneer een transactie aan het schrijven is, niemand anders naar dezelfde tabel kan schrijven totdat de transactie is voltooid. Er wordt namelijk een slot geplaatst op te tabel zolang deze bezet is. Het is duidelijk dat het werken met versienummers minder complexiteit met zich meebrengt dan het werken met locks. Daarom is de optimistische concurrency control performanter. Dat is echter enkel zo in een systeem waar de data niet veel aangepast wordt. Wanneer de data wel frequent aangepast wordt kan het zijn dat de optimistische aanpak juist minder performant wordt dan de pessimistische aanpak met de locks. Wanneer het systeem bij de validatie op het versienummer merkt dat de data veranderd is, moet de gehele transactie namelijk opnieuw gestart worden. De bedoeling van de optimistische aanpak is dat men over real-time search kan spreken. Wanneer men in een omgeving werkt met data die frequent verandert moet men rekening houden dat men de eigenschappen van real-time search kan verliezen. Een tweede manier om aan snelheid te winnen in een gedistribueerd systeem is caching. Elasticsearch doet vaak aan caching om niet telkens opnieuw alle data te moeten opvragen. Dat heeft een negatief effect op het geheugen dat het systeem nodig heeft maar ook een zeer positief effect op de uitvoeringstijd.

Het CAP theorema stelt dat het onmogelijk is voor een gedistribueerd systeem om gelijktijdig consistent (Consistent), beschikbaar (Available) en partitie tolerant (Partition tolerant) te zijn. Het stelt dat een gedistribueerd systeem tegelijk aan maximaal twee van de voornoemde eigenschappen kan voldoen. Consistent betekent dat alle nodes in de cluster dezelfde data zien op hetzelfde moment. Daarbij is het belangrijk dat deze data de meest recente data is. Men kan spreken over een beschikbaar systeem wanneer alle nodes een reponse kunnen geven voor alle requests. Wanneer een node geen response kan geven op een request wordt er niet aan de criteria voldaan om over een beschikbaar systeem te kunnen spreken. De laatste voorwaarde in het CAP theorema, partitie tolerant, houdt in dat het systeem correct blijft functioneren bij het uitvallen van een node in het netwerk. Volgens \textcite{Brasetvik2013} is het bij Elasticsearch over het algemeen zo dat het systeem consistent en partitie tolerant is. Dat noemt men een CP-systeem. Hierbij is het niet onbelangrijk om te vermelden dat er een zwakke definitie voor consistentie gebruikt wordt. Wat er precies gegarandeerd wordt is namelijk document consistentie waarbij er sprake is van consistentie binnen een document. Wanneer men Elasticsearch enkel gebruikt om data uit te lezen bereikt men een systeem dat beschikbaar en partitie tolerant is. Dat noemt men een AP-systeem.

\textcite{Glauner2012} schrijft dat één van de belangrijkste sterktes van de zoekmachine is dat het gebruik maakt van een schema-less data model. Hierdoor kan elk JSON document aan Elasticsearch toegevoegd worden. Dat zorgt voor veel flexibiliteit en minder configuratiewerk voor de gebruikers. \textcite{Brasetvik2013} gebruikt liever de term schema flexible. Er is namelijk wel een schema, alleen moet dat niet verplicht meegegeven worden. Het is perfect mogelijk dat een document enkele fields ontbreekt. Wanneer dat field gebruikt wordt in een zoekopdracht wordt het document niet meegenomen in de resultaten. De zoekmachine is zeer sterk in het herkennen van eenvoudige datatypes zoals nummers, booleans en timestamps. Daardoor kan er een impliciet schema gegenereerd worden zonder expliciet te moeten meegeven wat de datatypes zijn. De mogelijkheid om een schema mee te geven bestaat echter wel. Een reden om zelf een schema mee te geven is om de data op punt te stellen en zo de zoeksnelheden te doen laten stijgen.

\subsection{Apache Lucene}

Om een goed inzicht te krijgen in de architectuur en werking van Elasticsearch keert men beter eerst terug naar de basis. Die basis is Apache Lucene. Elasticsearch is namelijk een laag die bovenop Apache Lucene werd gebouwd. Wanneer de architectuur van Elasticsearch besproken wordt in sectie \ref{architectuur} zal het duidelijk worden waar Apache Lucene zich bevindt in die architectuur.

Apache Lucene is een gratis en open source full-text search Java library. De initiële release van de Java library werd uitgebracht in 1999. Lucene werd origineel in Java geschreven maar werd later ook beschikbaar gemaakt in verscheidene programmeertalen zoals: C++, C\#, Delphi, Perl, PHP, Python, en Ruby \autocite{Whissel2009}. Deze library kan in een project geladen worden waardoor de functies kunnen aangeroepen worden.

De oprichter van Lucene is Douglass Read Cutting, vaak Doug Cutting genoemd. Doug Cutting is niet enkel de oprichter van Lucene maar ook van Apache Hadoop en, samen met Mike Cafarella, Nutch.

\subsubsection{Features}

Er zijn een aantal features beschikbaar zoals: field searches, boolean operators, range searches en wildcard searches. Bij field searches kan de gebruiker specifiëren waar in het document er precies moet gezocht worden. Wanneer men een lijst van boeken van een specifieke auteur wil opvragen zal het systeem enkel naar het auteur veld kijken. Wanneer de naam van de auteur in bijvoorbeeld de titel voorkomt zal het boek niet in de zoekresultaten terechtkomen. De boolean operators laten de gebruiker toe om voorwaarden te combineren. Dat kan gerealiseerd worden door bijvoorbeeld de AND, OR en NOT operators te gebruiken. De AND en OR operators worden telkens tussen twee voorwaarden geplaatst om het resultaat te beïnvloeden. Ze geven aan dat er respectievelijk aan beide of minstens één voorwaarde moet voldaan worden vooraleer het document in de zoekresultaten terecht komt. De NOT operator hoort bij één voorwaarde en draait het resultaat van de voorwaarde om. Er kunnen haakjes rond de voorwaarden geplaatst worden om die te gaan groeperen.

Range searches laten toe om te gaan zoeken naar documents waarvan een bepaalde waarde tussen twee grenzen ligt. Zo kan men bijvoorbeeld zoeken naar alle personen met een leeftijd tussen 18 en 25 jaar. Bij wildcard searches wordt het mogelijk gemaakt om speciale symbolen mee te geven ter vervanging van tekst. Het ‘*’ symbool kan vervangen worden door meerdere karakters terwijl het ‘?’ symbool slechts door één karakter kan vervangen worden.

Verder zijn er nog andere features zoals het detecteren van sleutelwoorden, het verwijderen van stopwoorden, rekening houden met hoe dicht woorden bij elkaar staan.

Deze features bieden een zekere basisfunctionaliteit maar zijn niet altijd voldoende om aan elke use case te voldoen. Ook is het zo dat Apache Lucene geen zoekmachine is, maar een Java library. Volgens \textcite{Whissel2009} zijn er daarom verschillende projecten, waaronder Elasticsearch, die de bestaande features van Lucene uitbreiden of nieuwe features toevoegen. Ze gebruiken dus Apache Lucene als basis.

\subsubsection{Architectuur}

Een document stelt een record voor en bestaat uit een aantal fields waarbij zo’n field uit een aantal terms bestaat. Een term is een eenvoudig stukje tekst. Lucene slaat alle informatie van de documents, die het nodig heeft om te zoeken, op in bestanden die men indices noemt. Die indices worden onderverdeeld in segmenten. Bij een zoekopdracht zullen de segmenten individueel doorzocht worden waarna de resultaten gecombineerd worden. De inhoud van een segment kan nooit veranderen. Wanneer er een document verwijderd wordt zal deze nog steeds terug te vinden zijn in het segment waar het oorspronkelijk opgeslagen werd. Lucene houdt bij welke documents er verwijderd zijn. Dat gebeurt aan de hand van een bitmap. In een zoekopdracht worden de documents, waarvan in de bitmap terug te vinden is dat die verwijderd zijn, uit de resultaten gefilterd. Het is echter niet interessant om grote aantallen verwijderde documents te bewaren in het geheugen. Ook zijn er veel situaties waarbij documents niet enkel verwijderd, maar ook aangepast of toegevoegd worden. Daarom wordt er regelmatig een nieuw segment aangemaakt die de recentere data bevat. Standaard gebeurt dit elke second. Om een overhead aan segmenten tegen te gaan worden segmenten samengevoegd tot één segment waar mogelijk. Bij die samenvoeging worden documents die als verwijderd gemarkeerd staan in de bitmap niet meegenomen. Door dit fenomeen is het mogelijk dat een index kleiner wordt wanneer men er een document aan toevoegt. Het kan zijn dat het toevoegen van een document een reactie van het systeem uitlokt om segmenten te gaan samenvoegen tot één segment. \autocite{Brasetvik2017}

Tot nu toe werd er enkel gesproken over het opslaan van documents. Een document wordt echter niet zomaar opgeslagen. In plaats van volledige documents op te slaan wordt er informatie over de terms opgeslagen. Informatie die bijgehouden wordt is onder andere: het rangnummer van de term in het bijhorende field, de lengte van de term en de positie van de term in het field. In plaats van per document bij te houden welke terms erbij horen, wordt er een lijst gemaakt van welke documents bij welke term horen. Dit heet reverted indexing. Zo kan het systeem een term opzoeken en teruggeven welke documents bij de term horen. \autocite{Whissel2009}

De reverted index is niet zo'n interessant gegeven wanneer men een term van een vooraf bepaald document wil opzoeken. Daarom wordt er per document ook een stored field opgeslagen. Een stored field is een key-value store die de data van het document voorstelt. Op die manier moet de reverted index niet volledig doorlopen worden maar kan men rechtstreeks data van het specifieke document opvragen.

\subsection{Elasticsearch architectuur}
\label{architectuur}

Om dit onderzoek beter te begrijpen worden de belangrijkste termen uit het domein van Elasticsearch eerst kort besproken. In het boek van \textcite{Dixit2016} leert men hoe de achterliggende structuur van Elasticsearch in elkaar zit. Elasticsearch bestaat uit een cluster. De eerste cluster heeft standaard Elasticsearch als naam. Alle clusters samen stellen de data voor. In figuur \ref{fig:ESArchitecture} van \textcite{Babaev2013} is te zien hoe zo'n cluster in elkaar zit.

Een node is een instantie van Elasticsearch. Bij de creatie krijgt een node standaard een UUID en komt bij de Elasticsearch cluster tenzij anders gedefinieerd. Een UUID is een universally unique identifier en zorgt ervoor dat een node kan geïdentificeerd worden. Alle nodes in een cluster kennen elkaar en kunnen dus beroep doen op elkaar. Daarnaast heeft een node telkens één of meer rollen.

Een eerste rol die een node op zich kan nemen is om zich in aanmerking te stellen om de master node te zijn. De master node is verantwoordelijk voor kleine operaties die over de hele cluster lopen. Voorbeelden van zo’n operaties zijn: een index aanmaken, een index verwijderen, bijhouden welke nodes tot de cluster horen en beslissen in welke node een shard het best opgeslagen wordt. Een master node is zeer belangrijk voor de gezondheid van de cluster. Standaard is het zo dat alle nodes in aanmerking komen om de master node te zijn. Wanneer men een zoekopdracht uitvoert kan het zijn dat een node onder redelijk wat druk komt te staan. Om de master node zo goed mogelijk te laten functioneren is het een goed idee om de rollen zo te verdelen dat de master node geen data node is. Dat is vooral zo wanneer men met een grote cluster werkt.

De rol van data node is ook een rol die standaard voor elke node van toepassing is. Data nodes slaan de data op en voeren daar data-gerelateerde operaties op uit. Voorbeelden van zo’n operaties zijn: CRUD operaties, zoekoperaties en aggregaties. Naast deze twee belangrijkste rollen zijn er nog een aantal rollen die een node op zich kan nemen.

In de nodes zitten de indices. Een index is een verzameling van documents met gelijkaardige karakteristieken. Hier slaat Elasticsearch data in op. Een index kan zeer groot worden. Het kan gebeuren dat de index te groot wordt om op de schijf van een node op te slaan. Daarom bestaat een index uit meerdere shards en replicas. Deze worden door Elasticsearch voorzien om een index op te delen in stukken. Een shard in Elasticsearch stelt een Lucene index voor \autocite{Brasetvik2017}. Een Elasticsearch index bevat dus een verzameling van één of meerdere Lucene indices. Bij een zoekopdracht zullen de shards individueel doorzocht worden waarna de resultaten gecombineerd worden. Een shard kan een primaire shard of een secundaire shard zijn. Operaties die data aanpassen gebeuren op primaire shards. Secundaire shards bevatten kopies van de data van de primaire shards en zorgen ervoor dat het zoeken snel gebeurt. Kopies van data bewaren heeft ook als effect dat er sprake is van een hoge beschikbaarheid. Wanneer een primaire shard wordt stopgezet valt een secundaire shard in om de rol van de primaire shard te vervangen. Een veelgebruikt synoniem voor een secundaire shard is replica. In de shards kunnen de documents dan teruggevonden worden zoals in de architectuur van Lucene.

Eerder werd er vermeld dat Elasticsearch een gedistribueerd systeem is. Lucene is echter niet gemaakt om een gedistribueerd systeem te zijn. Het is de laag van Elasticsearch die ervoor zorgt dat er sprake is van een gedistribueerd systeem.

\begin{figure}
	\centering
	\includegraphics[width= 10cm]{ESArchitecture}
	\caption{Een cluster in Elasticsearch}
	\label{fig:ESArchitecture}
\end{figure}

\subsection{Schaalbaarheid}

Bij Elasticsearch is er sprake van horizontale schaalbaarheid \autocite{Dixit2016}. Dat wil zeggen dat een cluster opgedeeld wordt in verschillende nodes. De nodes kunnen zonder problemen op verschillende hardware functioneren. Een cluster kan dus uitgebreid worden zonder dat de complexiteit van het systeem toeneemt. Bij het toevoegen van een nieuwe node worden de shards verplaatst zodat de nodige opslagruimte minimaal blijft.

In de master thesis van \textcite{Berglund2013} wordt er een belangrijke stelling gemaakt over de schaalbaarheid van Elasticsearch. De search engine is zeer schaalbaar omdat de documents organisatorisch verdeeld zijn over verschillende nodes. Bij een specifieke zoekopdracht waarbij men zoekt op het document ID of het type zullen slechts enkele nodes moeten overlopen worden. Dat ideale scenario is echter niet altijd aan de orde. Afhankelijk van de criteria waarop men zoekt, kan het zijn dat alle nodes moeten overlopen worden. Dat is een limitatie van de schaalbaarheid van Elasticsearch. Dat probleem zou vandaag nog niet opgelost kunnen worden zonder dat er dataverlies voorkomt in de zoekresultaten. 

\subsection{Installatie}
\label{Installatie}

Elasticsearch is gratis wanneer men beslist om het zelf te hosten. De installatie verloopt zeer snel. Eerst moet men ervoor zorgen dat Java geïnstalleerd staat op het systeem. Daarna kan er een versie naar keuze van Elasticsearch gedownload worden via de website. Wanneer men het bestand uitpakt staat alles klaar om de eerste cluster op te starten. Als dat te moeilijk is kan men gebruik maken van een grafische user interface die beschikbaar is via de MSI installer package. Op de website staat stap voor stap uitgelegd hoe je de installatie kunt uitvoeren. 

Er hangen niet zoveel nadelen vast aan het zelf hosten van Elasticsearch. Men moet natuurlijk wel over voldoende ruimte beschikken op de harde schijf. Dat kan moeilijk worden wanneer men met grote hoeveelheden data werkt. Daarnaast is het belangrijk om te weten dat men zelf verantwoordelijk is voor eventuele downtimes. Het is dus perfect mogelijk om Elasticsearch volledig gratis te gebruiken. 

Wanneer men beslist om te betalen voor de hosting bij Elasticsearch beschikt men wel over enkele voordelen. De eerder vermelde problemen in verband met ruimte op je harde schijf en downtimes zijn niet langer van toepassing. Aan de externe hosting zijn er een aantal Service Level Agreements verbonden die ervoor zorgen dat men verzekerd is van een goede kwaliteit en dat men kan rekenen op voldoende support. De kostprijs begint met 36,53 EUR per maand. Er is ook een mogelijkheid om eerst een proefversie van 14 dagen te gebruiken.

\subsection{Data importeren in Elasticsearch}

Om data te exporteren van de databank naar Elasticsearch zijn er een aantal mogelijkheden, afhankelijk van welke databank er gebruikt wordt. De eerste mogelijkheid is er één die Elasticsearch zelf aanbiedt. Daarvoor maken ze gebruik van een ander product uit de Elastic Stack\footnote{De Elastic Stack is een verzameling van open-source producten van Elastic.}: Logstash. Logstash is een ETL-tool om data te verwerken, te transformeren en uit te wisselen. Het is een product waar veel informatie en support over te vinden is. Logstash is dus een tool die veel flexibiliteit biedt maar wel een extra installatie vergt. 

Daarnaast zijn er een aantal tools die aangeboden worden door de community. Voor die tools is er in het algemeen minder support te vinden. Nog een nadeel is dat het niet altijd mogelijk is om de data naar de laatste versie van Elasticsearch te exporteren. De versies van de tools lopen namelijk in het algemeen achter op de nieuwste versie van Elasticsearch. 

Zowel Logstash als de meeste tools die worden aangeboden door de community bieden ook de functionaliteit aan om data te synchroniseren. Dat wil zeggen dat, wanneer de data verandert in de databank, die veranderingen ook doorgevoerd worden in Elasticsearch. In veel use cases zal dit veel voordelen bieden. 

\subsection{Support}

Ook support is een zeer belangrijk aspect wanneer men overweegt om met Elasticsearch te werken. Een eerste onderdeel van support is de documentatie. Hoeveel informatie kan men vinden over de werking van Elasticsearch? Volgens \textcite{Glauner2012} was die documentatie in 2012 onvoldoende. Uit het project in hoofdstuk 3 zal blijken dat deze documentatie echter zeer uitgebreid geworden is. Ook staat er een grote community achter Elasticsearch die zeer bruikbare features aanbiedt. Verder zijn er talrijke boeken te vinden (\textcite{Turner}). Deze boeken reiken van boeken waar beginners mee aan de slag kunnen tot boeken waarmee experten hun kennis verder kunnen uitbreiden. Ook is er de mogelijkheid om persoonlijke support te krijgen voor een specifiek probleem. Daarvoor zal men wel moeten betalen.

\subsection{Gebruik van Elasticsearch}
\label{subsec:gebruikES}

Elasticsearch wordt door veel bedrijven momenteel gebruikt voor verschillende doeleinden. Die doeleinden kunnen gaan van logging tot het bestrijden van cyberaanvallen. Enkele opvallende gebruikers van Elasticsearch zijn NASA, Netflix, Github, Facebook, Cisco, Microsoft en Adobe. Deze zijn te vinden op de website van Elasticsearch.

Er kan met de REST API van Elasticsearch gecommuniceerd worden met behulp van elke web client die men prefereert. Men kan er zelf voor kiezen om deze tussenlaag over te slaan door de command line te gebruiken. Elasticsearch voorziet enkele clients die kunnen gebruikt worden in verschillende talen. Veelgebruikte talen zijn Curl, Java, C\#, Python, JavaScript, PHP, Perl en Ruby. Daarnaast biedt ook de community een uitgebreide waaier aan clients.

Elasticsearch biedt veel features zoals full text-search, completion suggesters, custom document scoring en meer. Bij full text-search geeft de gebruiker één of meerdere sleutelwoorden mee. Elasticsearch zal dan zoeken naar documents die de sleutelwoorden bevatten. Bij completion suggesters wordt opnieuw een sleutelwoord meegegeven door de gebruiker. Elasticsearch zal een lijst teruggeven met een aantal voorstellen van relevante sleutelwoorden die de gebruiker dan kan gebruiken om zijn zoektocht verder te zetten. Custom document scoring houdt in dat men zelf een functie kan meegeven die de relevantie van de zoekopdracht berekent. Variabelen die bijvoorbeeld een belangrijke rol kunnen spelen zijn de lengte van het veld, het aantal overeenkomsten en meer. Een uitgebreid aanbod aan features zorgt ervoor dat er meer kans is dat Elasticsearch aan de eisen van de use case voldoet. 

Van authorizatie is er echter weinig sprake. Iedere gebruiker van Elasticsearch heeft alle rechten \autocite{Brasetvik2013}. Wanneer men bijvoorbeeld met een team van ontwikkelaars werkt moet daar rekening mee gehouden worden. Het is dus zeker niet aangeraden om gevoelige data op te slaan in Elasticsearch. Er bestaat een plugin, genaamd Shield, die authorizatie aan Elasticsearch kan toevoegen. Die plugin is echter niet gratis. 

\subsection{Open source}

Elasticsearch is open source software. Dat heeft zo zijn voor- en nadelen. Iedereen kan aan de broncode om een bugfix te doen of om nieuwe features toe te voegen. Dat is zeer gunstig voor de groei van Elasticsearch. Daarnaast kan men de broncode ook aanpassen zodat er voldaan wordt aan eventuele specifieke noden van de gebruiker. \autocite{Tahir2008}

De community van Elasticsearch is groot en is zeer behulpzaam. Toch kan men daar niet altijd op vertrouwen. Wanneer men met een zeer specifiek probleem of een bug te maken heeft komt er niet altijd snel een kant en klaar antwoord. In zo'n geval staat men er alleen voor. Dat is in het algemeen zo bij open source software. Om professionele en persoonlijke hulp te krijgen zal men toch moeten betalen voor Elasticsearch.

\subsection{Alternatieven}

Er zijn heel wat alternatieven voor Elasticsearch op de markt. De meeste alternatieven bieden echter enkel functionaliteiten om data-analyses uit te voeren, om aan logging te doen of om een zoekfunctionaliteit te implementeren. Alternatieven die alle features van Elasticsearch kunnen vervangen zijn dus veel schaarser. Omdat deze bachelorproef de focus legt op data-analyse zal een alternatief vooral daarop beoordeeld worden. Dat neemt niet weg dat de zoekfunctionaliteit of de mogelijkheden van de logging verwaarloosd worden. Met deze laatste wordt er zeker rekening gehouden maar in die mate dat de data-analyse iets meer naar voor komt.

\subsubsection{Algolia}

Een eerste alternatief is Algolia. Algolia is een duurder product dat zich meer op de zoekfunctionaliteit focust. Een groot verschil met Elasticsearh is de security. In tegenstelling tot Elasticsearch bestaat er in Algolia de mogelijkheid om gebruikersrechten in te voeren \autocite{Algolia}. Zo kunnen bepaalde luiken van het product afgeschermd worden voor gebruikers die daar geen toegang mogen toe hebben. Die authorizatie wordt gedaan aan de hand van API keys. Verder zal Algolia het zoekgedrag gaan analyseren zonder dat daar extra configuraties aan te pas gaan. Dat zoekgedrag kan, afhankelijk van de use case, zeer interessante informatie opleveren. Evenals Elasticsearch biedt Algolia ook logging aan. Deze functionaliteit is echter meer uitgebreid in Elasticsearch dan in Algolia. Ook de grote waaier aan aggregaties is niet aanwezig in Algolia. Data-analyses worden dus beter in Elasticsearch gedaan terwijl Algolia meer hulp kan bieden bij zoekfunctionaliteiten.

\subsubsection{Apache Solr}

Een tweede alternatief is Apache Solr. Apache Solr wordt vaak gezien als de rivaal van Elasticsearch. Ook deze zoekmachine werd gebouwd met Apache Lucene als basis. Apache Solr is zeer vergelijkbaar met Elasticsearch maar wordt beschouwd als een volwassen technologie terwijl Elasticsearch een jongere technologie is. Voor logging biedt Elasticsearch meer mogelijkheden. Elasticsearch heeft een aantal oplossingen voor de limitaties in Solr. Die limitaties zijn ontstaan door zeer schaalbaar te willen zijn, een aspect waar Apache Solr dan weer beter in scoort dan Elasticsearch. Elasticsearch biedt meer features terwijl Apache Solr meer fout tolerant is en tegelijkertijd beter schaalt. \autocite{Solr}. Voor een eenvoudige maar robuuste zoekfunctionaliteit wordt Apache Solr aangeraden. Voor meer flexibiliteit wordt Elasticsearch aangeraden. Wanneer men met data werkt die snel verandert kan dat ook de keuze tussen de twee zoekmachines beïnvloeden. In het inleidende stuk van sectie \ref{sec:stand-van-zaken} werd er verteld dat de optimistische aanpak voor concurrency control nadelig kan zijn wanneer men met snel veranderende data werkt. Toch scoort Elasticsearch hier beter dan Solr. Dat komt omdat de caches van Solr globaal zijn. Wanneer er een verandering in de data optreedt wordt de hele cache ongeldig gemarkeerd. In Elasticsearch gebeurt de caching per segment waardoor er telkens kleine stukjes cache ongeldig gemarkeerd worden.

\subsubsection{Searchify}

Een derde alternatief is Searchify. Searchify beschikt, net als Elasticsearch, over een uitgebreid aanbod aan features. Veel van die features werden in beide zoekmachines op een andere manier geïmplementeerd maar men kan over het algemeen dezelfde resultaten bekomen. Een voorbeeld daarvan zijn de field weights in Searchify. Field weights laten de gebruiker toe om een gewicht mee te geven aan bepaalde fields in een document. Zo kan men specifiëren dat de titel van een boek een groter gewicht heeft dan de inhoud van het boek. Wanneer men nadien naar een term gaat zoeken zullen de boeken, waarvan de term in de titel zit, hoger scoren dan boeken waarvan de  term ergens in de tekst voorkomt. In Elasticsearch kan men een gelijkaardige logica bereiken met custom document scoring. Custom document scoring kwam eerder aan bod in de literatuurstudie in sectie \ref{subsec:gebruikES}. Deze feature is complexer in gebruik maar biedt meer mogelijkheden om de zoekresultaten te beïnvloeden. Beide zoekmachines zijn beschikbaar in verschillende programmeertalen. Een aspect waar Searchify een groot voordeel biedt over Elasticsearch zijn de real-time updates. Searchify is ideaal wanneer de data zeer frequent verandert. De zoekmachine werd gebouwd om aan de noden van een moderne web site te voldoen waar de data zeer snel verandert. Dat is het tegenovergestelde van Elasticsearch, waar data die veel verandert ervoor kan zorgen dat men niet meer over real-time search kan spreken. Eerder in de literatuurstudie werd vermeld dat dit komt door de optimistische concurrency control. Een groot nadeel van Searchify is dat het niet gratis gebruikt kan worden. De goedkoopste module begint met 50 EUR per maand.

\subsubsection{Swiftype}

Een vierde alternatief, die opvallend anders is dan de voorgaande alternatieven, is Swiftype. Swiftype wordt gelabeld als search as a service. Dat betekent dat je Swiftype kunt implementeren zonder enige code te moeten schrijven. Wanneer je Swiftype opzet kan het meteen gebruikt worden. Het geeft meteen relevante zoekresultaten terug. Deze kunnen natuurlijk wel aangepast worden naar de noden van de gebruiker. Dat kan op een eenvoudige manier worden bereikt aan de hand van drag-and-drop. Swiftype is dus zo gebruiksvriendelijk dat de gebruiker geen technische kennis nodig heeft, maar die indien gewenst toch kan toepassen.

Swiftype is een laag die boven Elasticsearch werd gebouwd en biedt dus vrijwel dezelfde features. Het kan in het algemeen meer maar is een relatief dure service. De prijs begint bij 255 EUR per maand. Het is wel zo dat de focus hier meer op zoekfunctionaliteiten ligt. Om een uitgebreide data-analyse uit te voeren kan met met Elasticsearch minstens evenveel. Elasticsearch is echter wel een gratis alternatief. Analyses over het zoeken is een ander verhaal. Met Swiftype kan, zonder extra configuratiewerk, zeer veel informatie over het zoeken terugvinden. Die informatie is bijvoorbeeld: waar in de wereld de zoekopdracht uitgevoerd werd, wat de meest gebruikte termen zijn en wat de piekuren voor zoekopdrachten zijn. Wanneer men een beslissing wil maken tussen Swiftype en Elasticsearch  moet men zich eigelijk gewoon afvragen of men de zoekmachine zelf wilt bouwen of wilt kopen.

Wanneer men de zoekmachine zelf bouwt is er meer ruimte voor maatwerk. Men kan specifieke zaken implementeren die aan noden voldoen die niet in elk standaardpakket zitten. Er is natuurlijk ook sprake van veel werk. Als uw project van korte duur is, of er zijn geen ontwikkelaars die aan de zoekmachine kunnen werken, is het beter om de zoekmachine als een service te kopen. Wanneer men de zoekmachine zelf gebouwd heeft moet met natuurlijk geen maandelijks bedrag meer betalen. Op lange termijn is dat financieel de beste keuze.

\subsubsection{Amazon CloudSearch}

Ook Amazon CloudSearch is search as a service. Amazon CloudSearch is een laag die boven Apache Solr werd gebouwd. Toch heeft de service niet alle beschikbare functies van Apache Solr meegenomen. Zo is er bijvoorbeeld geen autocomplete en kan men geen gebruik maken van completion suggesters. Amazon CloudSearch heeft wel als voordeel dat je enkel betaalt voor wat je gebruikt. Wanneer je de service niet meer gebruikt zal er ook niks meer aangerekend worden. Op hun website vergelijken ze het met het factureren van water of elektriciteit. Er zit een zeer handige feature in het Amazon CloudSearch die je niet overal terugvindt. Er kan namelijk gekozen worden welke waarden in het CAP-theorema het belangrijkst worden beschouwd door de gebruiker. Aan de hand van die instellingen zal het systeem ervoor zorgen dat er aan die waarden voldaan wordt. Een nadeel aan het alternatief is dat het niet open source is. Dat kan een reden zijn waarom er de laatste drie jaar geen nieuwe updates meer uitgekomen zijn.

\section{Probleemstelling en Onderzoeksvragen}
\label{sec:onderzoeksvragen}

%% TODO:
%% Uit je probleemstelling moet duidelijk zijn dat je onderzoek een meerwaarde
%% heeft voor een concrete doelgroep (bv. een bedrijf).
%%
%% Wees zo concreet mogelijk bij het formuleren van je
%% onderzoeksvra(a)g(en). Een onderzoeksvraag is trouwens iets waar nog
%% niemand op dit moment een antwoord heeft (voor zover je kan nagaan).

De laatste dertig jaar is data zeer belangrijk geworden voor bedrijven. Ze beschikken over steeds meer data en zoeken naar nieuwe manieren om daar gebruik van te maken. Zo nemen ze belangrijke beslissingen of trekken ze conclusies aan de hand van data-analyses. Een eerste beslissing die moet gemaakt worden bij het uitvoeren van data-analyses is welke tool er zal worden gebruikt. Dat is geen gemakkelijke, maar uiterst belangrijke keuze. Er zijn veel tools beschikbaar en ze hebben allemaal andere sterktes. Omdat die keuze afhankelijk is van de use case waarvoor het zal gebruikt worden bestaat er geen universeel antwoord op dit probleem. Men kan zich enkel baseren op subjectieve meningen van anderen of op beweringen van de ontwikkelaars van de tool. Het hoofddoel van dit onderzoek is om ondersteuning te bieden bij deze keuze. In veel van die gevallen wordt Elasticsearch overwogen. Daarom worden de voor- en nadelen van de zoekmachine onderzocht. Door dit onderzoek wordt het duidelijk welke vragen men zich moet stellen bij het kiezen voor Elasticsearch. Ook de ontwikkelaars van Elasticsearch kunnen met deze voor- en nadelen rekening houden in toekomstige updates.

\section{Opzet van deze bachelorproef}
\label{sec:opzet-bachelorproef}

%% TODO: Het is gebruikelijk aan het einde van de inleiding een overzicht te
%% geven van de opbouw van de rest van de tekst. Deze sectie bevat al een aanzet
%% die je kan aanvullen/aanpassen in functie van je eigen tekst.

De rest van deze bachelorproef is als volgt opgebouwd:

In Hoofdstuk~\ref{ch:methodologie} wordt het project dat werd uitgevoerd in Elasticsearch om voor- en nadelen te introduceren, bevestigen of ontkrachten beschreven.

In Hoofdstuk~\ref{ch:conclusie}, tenslotte, wordt de conclusie gegeven en een antwoord geformuleerd op de onderzoeksvraag. Daarbij wordt ook een aanzet gegeven voor toekomstig onderzoek binnen dit domein.

